{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c1f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5982ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c8364bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "factCovid = pd.read_csv('factCovid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f766c816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>hospitalizedcurrently</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizeddischarged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210219</td>\n",
       "      <td>PR</td>\n",
       "      <td>98624.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210218</td>\n",
       "      <td>PR</td>\n",
       "      <td>98506.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210217</td>\n",
       "      <td>PR</td>\n",
       "      <td>98428.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210216</td>\n",
       "      <td>PR</td>\n",
       "      <td>98317.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210215</td>\n",
       "      <td>PR</td>\n",
       "      <td>97837.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips province_state country_region  confirmed  deaths  recovered  active  \\\n",
       "0  72.0    Puerto Rico             US        3.0     0.0        0.0     NaN   \n",
       "1  72.0    Puerto Rico             US        3.0     0.0        0.0     NaN   \n",
       "2  72.0    Puerto Rico             US        3.0     0.0        0.0     NaN   \n",
       "3  72.0    Puerto Rico             US        3.0     0.0        0.0     NaN   \n",
       "4  72.0    Puerto Rico             US        3.0     0.0        0.0     NaN   \n",
       "\n",
       "       date state  positive  negative  hospitalizedcurrently  hospitalized  \\\n",
       "0  20210219    PR   98624.0  305972.0                  214.0           NaN   \n",
       "1  20210218    PR   98506.0  305972.0                  233.0           NaN   \n",
       "2  20210217    PR   98428.0  305972.0                  241.0           NaN   \n",
       "3  20210216    PR   98317.0  305972.0                  220.0           NaN   \n",
       "4  20210215    PR   97837.0  305972.0                  209.0           NaN   \n",
       "\n",
       "   hospitalizeddischarged  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factCovid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954dbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "factCovid.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ac90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "factCovidSchema = pd.io.sql.get_schema(factCovid.reset_index(),'factCovid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c0027c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"factCovid\" (\n",
      "\"index\" INTEGER,\n",
      "  \"fips\" REAL,\n",
      "  \"province_state\" TEXT,\n",
      "  \"country_region\" TEXT,\n",
      "  \"confirmed\" REAL,\n",
      "  \"deaths\" REAL,\n",
      "  \"recovered\" REAL,\n",
      "  \"active\" REAL,\n",
      "  \"date\" INTEGER,\n",
      "  \"state\" TEXT,\n",
      "  \"positive\" REAL,\n",
      "  \"negative\" REAL,\n",
      "  \"hospitalizedcurrently\" REAL,\n",
      "  \"hospitalized\" REAL,\n",
      "  \"hospitalizeddischarged\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(factCovidSchema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff58dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "247bf59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6cdeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b50a309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster.config']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.read('cluster.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4bb5934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.17.0.2'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['POSTGRES']['PG_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d719646",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = config['POSTGRES']['PG_DB']\n",
    "user = config['POSTGRES']['PG_UNAME']\n",
    "passwd = config['POSTGRES']['PG_PASS']\n",
    "port = config['POSTGRES']['PG_PORT']\n",
    "host = config['POSTGRES']['PG_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab47e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9e15950",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=host,dbname=db,user=user,password=passwd,port=port)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cce5b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9dffd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "except:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4da312ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE \"factcovid\" (\n",
    "        \"index\" NUMERIC,\n",
    "          \"fips\" NUMERIC,\n",
    "          \"province_state\" VARCHAR(255),\n",
    "          \"country_region\" VARCHAR(255),\n",
    "          \"confirmed\" NUMERIC,\n",
    "          \"deaths\" NUMERIC,\n",
    "          \"recovered\" NUMERIC,\n",
    "          \"active\" NUMERIC,\n",
    "          \"date\" NUMERIC,\n",
    "          \"state\" VARCHAR(255),\n",
    "          \"positive\" NUMERIC,\n",
    "          \"negative\" NUMERIC,\n",
    "          \"hospitalizedcurrently\" NUMERIC,\n",
    "          \"hospitalized\" NUMERIC,\n",
    "          \"hospitalizeddischarged\" NUMERIC\n",
    "        )\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4cc47445",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"\"\"\n",
    "        COPY factcovid from '/var/lib/postgresql/data/factCovid.csv'\n",
    "        DELIMITER ',' CSV HEADER\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "016b2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70d730c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 19:48:06 WARN Utils: Your hostname, codeStation resolves to a loopback address: 127.0.1.1; using 192.168.36.84 instead (on interface wlo1)\n",
      "22/10/31 19:48:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 19:48:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('dimreg1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f80ac58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimreg = spark.read.option('header','true').csv('dimReg1.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0329eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 19:50:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, province_state, country_region, latitude, longitude\n",
      " Schema: _c0, fips, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', fips=None, province_state='Anhui', country_region='China', latitude='31.826', longitude='117.226'),\n",
       " Row(_c0='1', fips=None, province_state='Beijing', country_region='China', latitude='40.182', longitude='116.414')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimreg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e8d2ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- fips: double (nullable = true)\n",
      " |-- province_state: string (nullable = true)\n",
      " |-- country_region: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimreg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5bb0f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'fips', 'province_state', 'country_region', 'latitude', 'longitude']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimreg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bb33e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|fips|\n",
      "+----+\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimreg.select(['fips']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "512554f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|latitude|longitude|\n",
      "+--------+---------+\n",
      "|  31.826|  117.226|\n",
      "|  40.182|  116.414|\n",
      "|  30.057|  107.874|\n",
      "|  26.079|  117.987|\n",
      "|  36.061|  103.834|\n",
      "|  23.342|  113.424|\n",
      "|   23.83|  108.788|\n",
      "|  26.815|  106.875|\n",
      "|  19.196|  109.745|\n",
      "|  38.043|  114.515|\n",
      "|  47.862|  127.761|\n",
      "|  33.882|  113.614|\n",
      "|    22.3|    114.2|\n",
      "|  30.976|  112.271|\n",
      "|   27.61|  111.709|\n",
      "|  44.093|  113.945|\n",
      "|  32.971|  119.455|\n",
      "|  27.614|  115.722|\n",
      "|  43.666|  126.192|\n",
      "|  41.296|  122.609|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimreg.select(['latitude','longitude']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a90d1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 19:54:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, province_state, country_region, latitude, longitude\n",
      " Schema: _c0, fips, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------+--------------------+------------------+-----------------+\n",
      "|summary|               _c0|              fips|province_state|      country_region|          latitude|        longitude|\n",
      "+-------+------------------+------------------+--------------+--------------------+------------------+-----------------+\n",
      "|  count|            222804|            198364|        208218|              222804|            222361|           222419|\n",
      "|   mean|          111401.5|31285.762537557217|          null|                null| 36.22746800473025|-78.0409227853748|\n",
      "| stddev|64318.119025668035|17118.692319266127|          null|                null|11.122844262895208|45.34682695389383|\n",
      "|    min|                 0|              72.0|   \"\"\"Bonaire\"| Sint Eustatius a...|           -52.368|         -170.132|\n",
      "|    max|            222803|           99999.0|      Zhejiang|            Zimbabwe|            71.707|          178.065|\n",
      "+-------+------------------+------------------+--------------+--------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimreg.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b00e54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimreg1 = dimreg.withColumn('fips_P2', dimreg['fips']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f832256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 19:56:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, province_state, country_region, latitude, longitude\n",
      " Schema: _c0, fips, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, fips=None, province_state='Anhui', country_region='China', latitude=31.826, longitude=117.226, fips_P2=None),\n",
       " Row(_c0=1, fips=None, province_state='Beijing', country_region='China', latitude=40.182, longitude=116.414, fips_P2=None)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimreg1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "353cb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimreg2 = dimreg1.drop('fips','fips_P2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3df8377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:02:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , province_state, country_region, latitude, longitude\n",
      " Schema: _c0, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, province_state='Anhui', country_region='China', latitude=31.826, longitude=117.226),\n",
       " Row(_c0=1, province_state='Beijing', country_region='China', latitude=40.182, longitude=116.414)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimreg2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f78b22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimreg3 = dimreg2.withColumnRenamed('_c0','fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1d73335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:05:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , province_state, country_region, latitude, longitude\n",
      " Schema: _c0, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(fips=0, province_state='Anhui', country_region='China', latitude=31.826, longitude=117.226),\n",
       " Row(fips=1, province_state='Beijing', country_region='China', latitude=40.182, longitude=116.414)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimreg3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b43714fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:06:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , province_state, country_region, latitude, longitude\n",
      " Schema: _c0, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n",
      "+----+--------------+--------------+--------+---------+\n",
      "|fips|province_state|country_region|latitude|longitude|\n",
      "+----+--------------+--------------+--------+---------+\n",
      "|   0|         Anhui|         China|  31.826|  117.226|\n",
      "|   1|       Beijing|         China|  40.182|  116.414|\n",
      "|   2|     Chongqing|         China|  30.057|  107.874|\n",
      "|   3|        Fujian|         China|  26.079|  117.987|\n",
      "|   4|         Gansu|         China|  36.061|  103.834|\n",
      "|   5|     Guangdong|         China|  23.342|  113.424|\n",
      "|   6|       Guangxi|         China|   23.83|  108.788|\n",
      "|   7|       Guizhou|         China|  26.815|  106.875|\n",
      "|   8|           Hai|         China|  19.196|  109.745|\n",
      "|   9|         Hebei|         China|  38.043|  114.515|\n",
      "|  10|  Heilongjiang|         China|  47.862|  127.761|\n",
      "|  11|            He|         China|  33.882|  113.614|\n",
      "|  12|     Hong Kong|     Hong Kong|    22.3|    114.2|\n",
      "|  13|         Hubei|         China|  30.976|  112.271|\n",
      "|  14|            Hu|         China|   27.61|  111.709|\n",
      "|  15|Inner Mongolia|         China|  44.093|  113.945|\n",
      "|  16|       Jiangsu|         China|  32.971|  119.455|\n",
      "|  17|       Jiangxi|         China|  27.614|  115.722|\n",
      "|  18|         Jilin|         China|  43.666|  126.192|\n",
      "|  19|      Liaoning|         China|  41.296|  122.609|\n",
      "+----+--------------+--------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimreg3.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "49e01972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCol='latitude',\n",
    "    outputCol=\"lat_imputed\",\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8cfa3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:13:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , province_state, country_region, latitude, longitude\n",
      " Schema: _c0, province_state, country_region, latitude, longitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg1.csv\n",
      "+----+--------------+--------------+--------+---------+-----------+\n",
      "|fips|province_state|country_region|latitude|longitude|lat_imputed|\n",
      "+----+--------------+--------------+--------+---------+-----------+\n",
      "|   0|         Anhui|         China|  31.826|  117.226|     31.826|\n",
      "|   1|       Beijing|         China|  40.182|  116.414|     40.182|\n",
      "|   2|     Chongqing|         China|  30.057|  107.874|     30.057|\n",
      "|   3|        Fujian|         China|  26.079|  117.987|     26.079|\n",
      "|   4|         Gansu|         China|  36.061|  103.834|     36.061|\n",
      "|   5|     Guangdong|         China|  23.342|  113.424|     23.342|\n",
      "|   6|       Guangxi|         China|   23.83|  108.788|      23.83|\n",
      "|   7|       Guizhou|         China|  26.815|  106.875|     26.815|\n",
      "|   8|           Hai|         China|  19.196|  109.745|     19.196|\n",
      "|   9|         Hebei|         China|  38.043|  114.515|     38.043|\n",
      "|  10|  Heilongjiang|         China|  47.862|  127.761|     47.862|\n",
      "|  11|            He|         China|  33.882|  113.614|     33.882|\n",
      "|  12|     Hong Kong|     Hong Kong|    22.3|    114.2|       22.3|\n",
      "|  13|         Hubei|         China|  30.976|  112.271|     30.976|\n",
      "|  14|            Hu|         China|   27.61|  111.709|      27.61|\n",
      "|  15|Inner Mongolia|         China|  44.093|  113.945|     44.093|\n",
      "|  16|       Jiangsu|         China|  32.971|  119.455|     32.971|\n",
      "|  17|       Jiangxi|         China|  27.614|  115.722|     27.614|\n",
      "|  18|         Jilin|         China|  43.666|  126.192|     43.666|\n",
      "|  19|      Liaoning|         China|  41.296|  122.609|     41.296|\n",
      "+----+--------------+--------------+--------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(dimreg3).transform(dimreg3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83447965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9575ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimhospital = spark.read.option('header','true').csv('dimhospital.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "996dab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:18:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      " Schema: _c0, fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimhospital.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, fips=4013.0, state_name='Arizona', hospital_name='Phoenix VA Health Care System (AKA Carl T Hayden VA Medical Center)', hospital_type='VA Hospital', hq_address='650 E Indian School Rd', hq_city='Phoenix', hq_state='AZ', latitude=33.49549780000007, longtitude=-112.06615689999995),\n",
       " Row(_c0=1, fips=4019.0, state_name='Arizona', hospital_name='Southern Arizona VA Health Care System', hospital_type='VA Hospital', hq_address='3601 S 6th Ave', hq_city='Tucson', hq_state='AZ', latitude=32.181263400000034, longtitude=-110.96588519999996)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimhospital.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7432cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:19:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      " Schema: _c0, fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimhospital.csv\n",
      "+---+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+------------------+-------------------+\n",
      "|_c0|   fips|          state_name|       hospital_name|       hospital_type|          hq_address|    hq_city|hq_state|          latitude|         longtitude|\n",
      "+---+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+------------------+-------------------+\n",
      "|  0| 4013.0|             Arizona|Phoenix VA Health...|         VA Hospital|650 E Indian Scho...|    Phoenix|      AZ| 33.49549780000007|-112.06615689999995|\n",
      "|  1| 4019.0|             Arizona|Southern Arizona ...|         VA Hospital|      3601 S 6th Ave|     Tucson|      AZ|32.181263400000034|-110.96588519999996|\n",
      "|  2| 6019.0|          California|VA Central Califo...|         VA Hospital|  2615 E Clinton Ave|     Fresno|      CA| 36.77332350000006|-119.77974209999996|\n",
      "|  3| 9009.0|         Connecticut|VA Connecticut He...|         VA Hospital|    950 Campbell Ave| West Haven|      CT| 41.28440040000004| -72.95761029999994|\n",
      "|  4|10003.0|            Delaware|Wilmington VA Med...|         VA Hospital|   1601 Kirkwood Hwy| Wilmington|      DE| 39.74020630000007| -75.60653249999996|\n",
      "|  5|11001.0|District of Columbia|Washington DC VA ...|         VA Hospital|     50 Irving St Nw| Washington|      DC| 38.93068230000006| -77.01119479999994|\n",
      "|  6|12001.0|             Florida|North Florida/Sou...|         VA Hospital|   1601 Sw Archer Rd|Gainesville|      FL|29.636988900000063|         -82.345254|\n",
      "|  7|16001.0|               Idaho|Boise VA Medical ...|         VA Hospital|       500 W Fort St|      Boise|      ID|         43.621035|       -116.1901845|\n",
      "|  8|22017.0|           Louisiana|Overton Brooks VA...|         VA Hospital|    510 E Stoner Ave| Shreveport|      LA| 32.50310080000003| -93.72168259999997|\n",
      "|  9|28121.0|         Mississippi|Merit Health Rive...|Short Term Acute ...|  1030 River Oaks Dr|    Flowood|      MS| 32.32548710000003| -90.10530849999998|\n",
      "| 10|29019.0|            Missouri|Harry S Truman Me...|         VA Hospital|     800 Hospital Dr|   Columbia|      MO| 38.93723540000008| -92.32884869999998|\n",
      "| 11|35001.0|          New Mexico|New Mexico VA Hea...|         VA Hospital|1501 San Pedro Dr Se|Albuquerque|      NM|35.055193100000054|       -106.5816425|\n",
      "| 12|36001.0|            New York|Albany Stratton V...|         VA Hospital|     113 Holland Ave|     Albany|      NY|42.649612700000034| -73.77444039999995|\n",
      "| 13|36005.0|            New York|James J Peters VA...|         VA Hospital|130 W Kingsbridge Rd|      Bronx|      NY| 40.86740320000007| -73.90640459999997|\n",
      "| 14|38017.0|        North Dakota|Fargo VA Health C...|         VA Hospital|       2101 Elm St N|      Fargo|      ND| 46.90593280000007|          -96.77453|\n",
      "| 15|41019.0|              Oregon|Roseburg VA Healt...|         VA Hospital|913 Nw Garden Val...|   Roseburg|      OR| 43.22706920000008|-123.36505739999996|\n",
      "| 16|42003.0|        Pennsylvania|VA Pittsburgh Hea...|         VA Hospital|  4100 Allequippa St| Pittsburgh|      PA| 40.44626610000006| -79.96080739999996|\n",
      "|103| 2020.0|              Alaska|Providence Alaska...|Short Term Acute ...|  3200 Providence Dr|  Anchorage|      AK| 61.18790490000004|-149.81691369999996|\n",
      "|104| 2020.0|              Alaska|Alaska Regional H...|Short Term Acute ...|      2801 Debarr Rd|  Anchorage|      AK| 61.21069310000007|-149.82873329999998|\n",
      "|105| 2020.0|              Alaska|Alaska Native Med...|Short Term Acute ...|   4315 Diplomacy Dr|  Anchorage|      AK| 61.18296470000007|-149.79996729999996|\n",
      "+---+-------+--------------------+--------------------+--------------------+--------------------+-----------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimhospital.filter(\"fips >= 2000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f59aa9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:22:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      " Schema: _c0, fips, state_name, hospital_name, hospital_type, hq_address, hq_city, hq_state, latitude, longtitude\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimhospital.csv\n",
      "+---+------+----------+--------------------+--------------------+--------------------+-------------+--------+------------------+-------------------+\n",
      "|_c0|  fips|state_name|       hospital_name|       hospital_type|          hq_address|      hq_city|hq_state|          latitude|         longtitude|\n",
      "+---+------+----------+--------------------+--------------------+--------------------+-------------+--------+------------------+-------------------+\n",
      "|  0|4013.0|   Arizona|Phoenix VA Health...|         VA Hospital|650 E Indian Scho...|      Phoenix|      AZ| 33.49549780000007|-112.06615689999995|\n",
      "|  1|4019.0|   Arizona|Southern Arizona ...|         VA Hospital|      3601 S 6th Ave|       Tucson|      AZ|32.181263400000034|-110.96588519999996|\n",
      "|103|2020.0|    Alaska|Providence Alaska...|Short Term Acute ...|  3200 Providence Dr|    Anchorage|      AK| 61.18790490000004|-149.81691369999996|\n",
      "|104|2020.0|    Alaska|Alaska Regional H...|Short Term Acute ...|      2801 Debarr Rd|    Anchorage|      AK| 61.21069310000007|-149.82873329999998|\n",
      "|105|2020.0|    Alaska|Alaska Native Med...|Short Term Acute ...|   4315 Diplomacy Dr|    Anchorage|      AK| 61.18296470000007|-149.79996729999996|\n",
      "|106|2050.0|    Alaska|Yukon-Kuskokwim D...|Short Term Acute ...|829 Chief Eddie H...|       Bethel|      AK|           60.7494|          -161.7271|\n",
      "|108|2090.0|    Alaska|Fairbanks Memoria...|Short Term Acute ...|      1650 Cowles St|    Fairbanks|      AK| 64.83115690000005|-147.73994709999997|\n",
      "|109|2110.0|    Alaska|Bartlett Regional...|Short Term Acute ...|    3260 Hospital Dr|       Juneau|      AK| 58.32901640000006|-134.46491669999995|\n",
      "|110|2122.0|    Alaska|Central Peninsula...|Short Term Acute ...|     250 Hospital Pl|     Soldotna|      AK| 60.49336990000006|-151.07825209999996|\n",
      "|111|2122.0|    Alaska|Providence Seward...|Critical Access H...|         417 1st Ave|       Seward|      AK|          60.26951|        -149.388742|\n",
      "|112|2122.0|    Alaska|South Peninsula H...|Critical Access H...|    4300 Bartlett St|        Homer|      AK| 59.65215050000006|-151.55003389999996|\n",
      "|113|2130.0|    Alaska|PeaceHealth Ketch...|Critical Access H...|    3100 Tongass Ave|    Ketchikan|      AK| 55.35365710000008|       -131.6866346|\n",
      "|115|2150.0|    Alaska|Providence Kodiak...|Critical Access H...|   1915 E Rezanof Dr|       Kodiak|      AK| 57.80088370000004|-152.37564719999995|\n",
      "|116|2170.0|    Alaska|Mat-Su Regional M...|Short Term Acute ...|2500 S Woodworth ...|       Palmer|      AK| 61.56316030000005|-149.25763829999997|\n",
      "|117|2180.0|    Alaska|Norton Sound Regi...|Critical Access H...|1000 Greg Krusche...|         Nome|      AK|         64.497393|         -165.40595|\n",
      "|118|2220.0|    Alaska|Mt Edgecumbe Hosp...|Critical Access H...|      222 Tongass Dr|        Sitka|      AK| 57.05199030000006|-135.35519879999998|\n",
      "|119|2275.0|    Alaska|Wrangell Medical ...|Critical Access H...|      310 Bennett St|     Wrangell|      AK|           56.3147|          -131.7229|\n",
      "|122|4001.0|   Arizona|Fort Defiance Ind...|Short Term Acute ...|Intersection of R...|Fort Defiance|      AZ|         35.759317|-109.04839919999996|\n",
      "|123|4001.0|   Arizona|Chinle Comprehens...|Short Term Acute ...|         Highway 191|       Chinle|      AZ|           36.1542|          -109.5526|\n",
      "|124|4001.0|   Arizona|Sage Memorial Hos...|Critical Access H...|     US-191 & AZ-264|       Ganado|      AZ|           35.6053|          -109.4589|\n",
      "+---+------+----------+--------------------+--------------------+--------------------+-------------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimhospital.filter((dimhospital['fips']<=5700) & (dimhospital['fips'] > 2000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "359ad4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regulation = spark.read.csv('dimReg2.csv',header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "54098494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:27:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, county, state\n",
      " Schema: _c0, fips, county, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, fips=53077.0, county='Yakima', state='Washington'),\n",
       " Row(_c0=1, fips=54001.0, county='Barbour', state='West Virginia')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0fe26757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|        county|count|\n",
      "+--------------+-----+\n",
      "|         Tyler| 1537|\n",
      "|East Feliciana|  779|\n",
      "|     Worcester| 1582|\n",
      "|        Aitkin|  757|\n",
      "|     Petroleum|  586|\n",
      "|      Thurston| 1543|\n",
      "|         Bucks|  794|\n",
      "|        Grimes|  780|\n",
      "|          Utah|  790|\n",
      "|       Hanover|  793|\n",
      "|         Izard|  768|\n",
      "|         Pasco|  795|\n",
      "|        Hawaii|  788|\n",
      "|      Montcalm|  793|\n",
      "|     Oktibbeha|  783|\n",
      "|       Shannon|  717|\n",
      "|    Deer Lodge|  776|\n",
      "|       Gilliam|  679|\n",
      "|        Caguas|  739|\n",
      "|    Charleston|  799|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regulation.groupBy('county').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d6896009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 20:29:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fips, state\n",
      " Schema: _c0, fips, state\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///run/media/solverbot/repoA/gitFolders/DEtheHardWay/dimReg2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+\n",
      "|               state|    sum(_c0)|    sum(fips)|\n",
      "+--------------------+------------+-------------+\n",
      "|                Utah| 28780298919| 1.08570141E9|\n",
      "|              Hawaii|  4760226343|  5.5338432E7|\n",
      "|           Minnesota| 84873200010|1.817647672E9|\n",
      "|                Ohio| 85860935839|2.683853682E9|\n",
      "|Northern Mariana ...|  2391754508|  1.0035327E8|\n",
      "|            Arkansas| 73502504741| 2.95607797E8|\n",
      "|              Oregon| 34583426977|1.139855057E9|\n",
      "|               Texas|244263926956|9.336975802E9|\n",
      "|        North Dakota| 51560439334| 1.51383607E9|\n",
      "|        Pennsylvania| 65003760414|2.205951373E9|\n",
      "|         Connecticut|  8730197645|  5.6894406E7|\n",
      "|            Nebraska| 88301904981|2.137219674E9|\n",
      "|             Vermont| 14582546321| 5.48953718E8|\n",
      "|      American Samoa|   251491011|         null|\n",
      "|              Nevada| 16156226090| 4.08602573E8|\n",
      "|         Puerto Rico| 75652585523|4.151978944E9|\n",
      "|          Washington| 38210825916|1.628990281E9|\n",
      "|            Illinois| 99552038754|1.348233671E9|\n",
      "|            Oklahoma| 75192217027|2.375887921E9|\n",
      "|      Virgin Islands|  3050035769|  1.7975808E8|\n",
      "+--------------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regulation.groupBy('state').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation.agg({ })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1aecef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricityGeneration = spark.read.csv('Electricity generation.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7dcac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-----+-----------+--------+-----+-------+-------+----------+--------+-------------+----+------+-------------+\n",
      "|Country|Year|   Coal|  Oil|Natural gas|Biofuels|Waste|Nuclear|  Hydro|Geothermal|Solar PV|Solar thermal|Tide|  Wind|Other sources|\n",
      "+-------+----+-------+-----+-----------+--------+-----+-------+-------+----------+--------+-------------+----+------+-------------+\n",
      "|    USA|2018|1254542|38825|    1513414|   58955|18259| 841329| 315619|     18962|   87183|         4640|null|277918|         5263|\n",
      "|     UK|2018|  17570| 1682|     131482|   32086| 8023|  65064|   7963|     57116|   12922|         null|   8|  null|         null|\n",
      "|    SWE|2018|   2035|  379|        564|    9338| 2539|  65801|  61605|     16623|     404|         null|null|  null|         null|\n",
      "|    RUS|2017| 174568| 6976|     518660|      84| 2594| 203143| 187131|       435|     558|         null|null|   140|         null|\n",
      "|    CHN|2017|4508568|10278|     196400|   79537|13386| 248070|1189840|       125|  130659|           29|  11|295025|         null|\n",
      "|    BRA|2017|  25337|15917|      65593|   52255| null|  15739| 370906|      null|     832|         null|null| 42373|          447|\n",
      "+-------+----+-------+-----+-----------+--------+-----+-------+-------+----------+--------+-------------+----+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "electricityGeneration.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2ef00671",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_earth = electricityGeneration.select(['Year','Coal','Oil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6383cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Year=2018, Coal=1254542, Oil=38825),\n",
       " Row(Year=2018, Coal=17570, Oil=1682),\n",
       " Row(Year=2018, Coal=2035, Oil=379),\n",
       " Row(Year=2017, Coal=174568, Oil=6976),\n",
       " Row(Year=2017, Coal=4508568, Oil=10278)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_earth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4a0ada97",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricty_total = electricity_earth.withColumn('totalGen',electricity_earth['Coal'] + electricity_earth['Oil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a4a96d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Year=2018, Coal=1254542, Oil=38825, totalGen=1293367),\n",
       " Row(Year=2018, Coal=17570, Oil=1682, totalGen=19252),\n",
       " Row(Year=2018, Coal=2035, Oil=379, totalGen=2414),\n",
       " Row(Year=2017, Coal=174568, Oil=6976, totalGen=181544),\n",
       " Row(Year=2017, Coal=4508568, Oil=10278, totalGen=4518846)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricty_total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e59a9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureAssembler = VectorAssembler(inputCols=['Year','Coal','Oil'], outputCol='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c7c771d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile = featureAssembler.transform(electricty_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "83dcf777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+--------+--------------------+\n",
      "|Year|   Coal|  Oil|totalGen|         independent|\n",
      "+----+-------+-----+--------+--------------------+\n",
      "|2018|1254542|38825| 1293367|[2018.0,1254542.0...|\n",
      "|2018|  17570| 1682|   19252|[2018.0,17570.0,1...|\n",
      "|2018|   2035|  379|    2414|[2018.0,2035.0,37...|\n",
      "|2017| 174568| 6976|  181544|[2017.0,174568.0,...|\n",
      "|2017|4508568|10278| 4518846|[2017.0,4508568.0...|\n",
      "|2017|  25337|15917|   41254|[2017.0,25337.0,1...|\n",
      "+----+-------+-----+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputFile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8338d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = outputFile.select('independent','totalGen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c9a2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|         independent|totalGen|\n",
      "+--------------------+--------+\n",
      "|[2018.0,1254542.0...| 1293367|\n",
      "|[2018.0,17570.0,1...|   19252|\n",
      "|[2018.0,2035.0,37...|    2414|\n",
      "|[2017.0,174568.0,...|  181544|\n",
      "|[2017.0,4508568.0...| 4518846|\n",
      "|[2017.0,25337.0,1...|   41254|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "091096db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "de33717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = finalData.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "49208887",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(featuresCol='independent', labelCol='totalGen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c53c84d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 21:12:40 WARN Instrumentation: [7368f4b5] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 56:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 21:12:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/31 21:12:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 21:12:41 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "regressor = regressor.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ec82967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-570.6127, 0.9999, 1.0045])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae49e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresResult = regressor.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ba4efb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------------+\n",
      "|         independent|totalGen|        prediction|\n",
      "+--------------------+--------+------------------+\n",
      "|[2017.0,25337.0,1...|   41254| 41887.89314938639|\n",
      "|[2017.0,174568.0,...|  181544|182117.23288962513|\n",
      "|[2018.0,2035.0,37...|    2414| 2410.219358005561|\n",
      "+--------------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regresResult.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "14ff52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ff27fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='Year',outputCol='yearIndex')\n",
    "newDf = indexer.fit(electricity_earth).transform(electricity_earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ef904eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+---------+\n",
      "|Year|   Coal|  Oil|yearIndex|\n",
      "+----+-------+-----+---------+\n",
      "|2018|1254542|38825|      1.0|\n",
      "|2018|  17570| 1682|      1.0|\n",
      "|2018|   2035|  379|      1.0|\n",
      "|2017| 174568| 6976|      0.0|\n",
      "|2017|4508568|10278|      0.0|\n",
      "|2017|  25337|15917|      0.0|\n",
      "+----+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDf.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
